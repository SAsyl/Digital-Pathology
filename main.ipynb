{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atqZGIIyNSBb"
      },
      "source": [
        "#**Практическое задание №1**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ga5g3lUhNNBy"
      },
      "source": [
        "Установка необходимых пакетов:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGBk36LpukIu"
      },
      "outputs": [],
      "source": [
        "!pip install -q tqdm\n",
        "!pip install --upgrade --no-cache-dir gdown"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vQDLyHEO1Ux"
      },
      "source": [
        "Монтирование Вашего Google Drive к текущему окружению:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5G5KkA1Nu5M9"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Num5lHV6912"
      },
      "source": [
        "Константы, которые пригодятся в коде далее, и ссылки (gdrive идентификаторы) на предоставляемые наборы данных:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ab2yCwDm7Fqb"
      },
      "outputs": [],
      "source": [
        "EVALUATE_ONLY = True\n",
        "TEST_ON_LARGE_DATASET = True\n",
        "TISSUE_CLASSES = ('ADI', 'BACK', 'DEB', 'LYM', 'MUC', 'MUS', 'NORM', 'STR', 'TUM')\n",
        "DATASETS_LINKS = {\n",
        "    'train': '1XtQzVQ5XbrfxpLHJuL0XBGJ5U7CS-cLi',\n",
        "    'train_small': '1qd45xXfDwdZjktLFwQb-et-mAaFeCzOR',\n",
        "    'train_tiny': '1I-2ZOuXLd4QwhZQQltp817Kn3J0Xgbui',\n",
        "    'test': '1RfPou3pFKpuHDJZ-D9XDFzgvwpUBFlDr',\n",
        "    'test_small': '1wbRsog0n7uGlHIPGLhyN-PMeT2kdQ2lI',\n",
        "    'test_tiny': '1viiB0s041CNsAK4itvX8PnYthJ-MDnQc'\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgY-ux5qOI0k"
      },
      "source": [
        "Импорт необходимых зависимостей:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLHQhqiSIyvK"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import numpy as np\n",
        "from typing import List\n",
        "from tqdm.notebook import tqdm\n",
        "from time import sleep\n",
        "from PIL import Image\n",
        "import IPython.display\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "import gdown"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKLI3lUyMYO9"
      },
      "source": [
        "---\n",
        "### Класс Dataset\n",
        "\n",
        "Предназначен для работы с наборами данных, обеспечивает чтение изображений и соответствующих меток, а также формирование пакетов (батчей)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8N169efsw1ej"
      },
      "outputs": [],
      "source": [
        "class Dataset:\n",
        "\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.is_loaded = False\n",
        "        url = f\"https://drive.google.com/uc?export=download&confirm=pbef&id={DATASETS_LINKS[name]}\"\n",
        "        output = f'{name}.npz'\n",
        "        gdown.download(url, output, quiet=False)\n",
        "        print(f'Loading dataset {self.name} from npz.')\n",
        "        np_obj = np.load(f'{name}.npz')\n",
        "        self.images = np_obj['data']\n",
        "        self.labels = np_obj['labels']\n",
        "        self.n_files = self.images.shape[0]\n",
        "        self.is_loaded = True\n",
        "        print(f'Done. Dataset {name} consists of {self.n_files} images.')\n",
        "\n",
        "    def image(self, i):\n",
        "        # read i-th image in dataset and return it as numpy array\n",
        "        if self.is_loaded:\n",
        "            return self.images[i, :, :, :]\n",
        "\n",
        "    def images_seq(self, n=None):\n",
        "        # sequential access to images inside dataset (is needed for testing)\n",
        "        for i in range(self.n_files if not n else n):\n",
        "            yield self.image(i)\n",
        "\n",
        "    def random_image_with_label(self):\n",
        "        # get random image with label from dataset\n",
        "        i = np.random.randint(self.n_files)\n",
        "        return self.image(i), self.labels[i]\n",
        "  \n",
        "    def random_batch_with_labels(self, n):\n",
        "        # create random batch of images with labels (is needed for training)\n",
        "        indices = np.random.choice(self.n_files, n)\n",
        "        imgs = []\n",
        "        for i in indices:\n",
        "            img = self.image(i)\n",
        "            imgs.append(self.image(i))\n",
        "        logits = np.array([self.labels[i] for i in indices])\n",
        "        return np.stack(imgs), logits\n",
        "\n",
        "    def image_with_label(self, i: int):\n",
        "        # return i-th image with label from dataset\n",
        "        return self.image(i), self.labels[i]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-LvGqeHYgus"
      },
      "source": [
        "### Пример использвания класса Dataset\n",
        "Загрузим обучающий набор данных, получим произвольное изображение с меткой. После чего визуализируем изображение, выведем метку. В будущем, этот кусок кода можно закомментировать или убрать."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HhObWEjGJ1um"
      },
      "outputs": [],
      "source": [
        "d_train_tiny = Dataset('train_tiny')\n",
        "\n",
        "img, lbl = d_train_tiny.random_image_with_label()\n",
        "print()\n",
        "print(f'Got numpy array of shape {img.shape}, and label with code {lbl}.')\n",
        "print(f'Label code corresponds to {TISSUE_CLASSES[lbl]} class.')\n",
        "\n",
        "pil_img = Image.fromarray(img)\n",
        "IPython.display.display(pil_img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaBXXCWeVLYb"
      },
      "source": [
        "---\n",
        "### Класс Metrics\n",
        "\n",
        "Реализует метрики точности, используемые для оценивания модели:\n",
        "1. точность,\n",
        "2. сбалансированную точность."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5unQ7azTinCZ"
      },
      "outputs": [],
      "source": [
        "class Metrics:\n",
        "\n",
        "    @staticmethod\n",
        "    def accuracy(gt: List[int], pred: List[int]):\n",
        "        assert len(gt) == len(pred), 'gt and prediction should be of equal length'\n",
        "        return sum(int(i[0] == i[1]) for i in zip(gt, pred)) / len(gt)\n",
        "\n",
        "    @staticmethod\n",
        "    def accuracy_balanced(gt: List[int], pred: List[int]):\n",
        "        return balanced_accuracy_score(gt, pred)\n",
        "\n",
        "    @staticmethod\n",
        "    def print_all(gt: List[int], pred: List[int], info: str):\n",
        "        print(f'metrics for {info}:')\n",
        "        print('\\t accuracy {:.4f}:'.format(Metrics.accuracy(gt, pred)))\n",
        "        print('\\t balanced accuracy {:.4f}:'.format(Metrics.accuracy_balanced(gt, pred)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1AHzTJVGU5k"
      },
      "source": [
        "---\n",
        "### Класс Model\n",
        "\n",
        "Класс, хранящий в себе всю информацию о модели.\n",
        "\n",
        "Вам необходимо реализовать методы save, load для сохранения и заргрузки модели. Особенно актуально это будет во время тестирования на дополнительных наборах данных.\n",
        "\n",
        "> *Пожалуйста, убедитесь, что сохранение и загрузка модели работает корректно. Для этого обучите модель, протестируйте, сохраните ее в файл, перезапустите среду выполнения, загрузите обученную модель из файла, вновь протестируйте ее на тестовой выборке и убедитесь в том, что получаемые метрики совпадают с полученными для тестовой выбрки ранее.*\n",
        "\n",
        "\n",
        "Также, Вы можете реализовать дополнительные функции, такие как:\n",
        "1. валидацию модели на части обучающей выборки;\n",
        "2. использование кроссвалидации;\n",
        "3. автоматическое сохранение модели при обучении;\n",
        "4. загрузку модели с какой-то конкретной итерации обучения (если используется итеративное обучение);\n",
        "5. вывод различных показателей в процессе обучения (например, значение функции потерь на каждой эпохе);\n",
        "6. построение графиков, визуализирующих процесс обучения (например, график зависимости функции потерь от номера эпохи обучения);\n",
        "7. автоматическое тестирование на тестовом наборе/наборах данных после каждой эпохи обучения (при использовании итеративного обучения);\n",
        "8. автоматический выбор гиперпараметров модели во время обучения;\n",
        "9. сохранение и визуализацию результатов тестирования;\n",
        "10. Использование аугментации и других способов синтетического расширения набора данных (дополнительным плюсом будет обоснование необходимости и обоснование выбора конкретных типов аугментации)\n",
        "11. и т.д.\n",
        "\n",
        "Полный список опций и дополнений приведен в презентации с описанием задания.\n",
        "\n",
        "При реализации дополнительных функций допускается добавление параметров в существующие методы и добавление новых методов в класс модели."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0pkMiB6mJ7JQ"
      },
      "outputs": [],
      "source": [
        "class Model:\n",
        "\n",
        "    def __init__(self):\n",
        "        # todo\n",
        "        pass\n",
        "\n",
        "    def save(self, name: str):\n",
        "        # todo\n",
        "        # pass\n",
        "        # example demonstrating saving the model to PROJECT_DIR folder on gdrive with name 'name'\n",
        "        arr = np.array([1, 2, 3, 4, 5], dtype=np.float32)\n",
        "        np.savez(f'/content/drive/MyDrive/{name}.npz', data=arr)\n",
        "\n",
        "    def load(self, name: str):\n",
        "        # todo\n",
        "        pass\n",
        "        # example demonstrating loading the model with name 'name' from gdrive using link\n",
        "        name_to_id_dict = {\n",
        "            'best': '1S8bwrVgvtSzadEX2aLlyb3VTlD31UI4R'\n",
        "        }\n",
        "        output = f'{name}.npz'\n",
        "        gdown.download(f'https://drive.google.com/uc?id={name_to_id_dict[name]}', output, quiet=False)\n",
        "        np_obj = np.load(f'{name}.npz')\n",
        "        print(np_obj['data'])\n",
        "\n",
        "    def train(self, dataset: Dataset):\n",
        "        # you can add some plots for better visualization,\n",
        "        # you can add model autosaving during training,\n",
        "        # etc.\n",
        "        print(f'training started')\n",
        "        # to-do\n",
        "        sleep(2)\n",
        "        print(f'training done')\n",
        "        pass\n",
        "\n",
        "    def test_on_dataset(self, dataset: Dataset, limit=None):\n",
        "        # you can upgrade this code if you want to speed up testing using batches\n",
        "        predictions = []\n",
        "        n = dataset.n_files if not limit else int(dataset.n_files * limit)\n",
        "        for img in tqdm(dataset.images_seq(n), total=n):\n",
        "            predictions.append(self.test_on_image(img))\n",
        "        return predictions\n",
        "\n",
        "    def test_on_image(self, img: np.ndarray):\n",
        "        # todo: replace this code\n",
        "        prediction = np.random.randint(9)\n",
        "        sleep(0.05)\n",
        "        return prediction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMpTB6lMr00A"
      },
      "source": [
        "---\n",
        "### Классификация изображений\n",
        "\n",
        "Используя введенные выше классы можем перейти уже непосредственно к обучению модели классификации изображений. Пример общего пайплайна решения задачи приведен ниже. Вы можете его расширять и улучшать. В данном примере используются наборы данных 'train_small' и 'test_small'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cTOuZD01Up6"
      },
      "outputs": [],
      "source": [
        "d_train = Dataset('train_small')\n",
        "d_test = Dataset('test_small')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBi0XpXg8_wq"
      },
      "outputs": [],
      "source": [
        "model = Model()\n",
        "if not EVALUATE_ONLY:\n",
        "    model.train(d_train)\n",
        "    model.save('best')\n",
        "else:\n",
        "    #todo: your link goes here\n",
        "    model.load('best')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcM2EiRMVP93"
      },
      "source": [
        "Пример тестирования модели на части набора данных:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0AqmeLEKqrs"
      },
      "outputs": [],
      "source": [
        "# evaluating model on 10% of test dataset\n",
        "pred_1 = model.test_on_dataset(d_test, limit=0.1)\n",
        "Metrics.print_all(d_test.labels[:len(pred_1)], pred_1, '10% of test')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSwvHVVzVWZ5"
      },
      "source": [
        "Пример тестирования модели на полном наборе данных:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjI_sbMi3TMY"
      },
      "outputs": [],
      "source": [
        "# evaluating model on full test dataset (may take time)\n",
        "if TEST_ON_LARGE_DATASET:\n",
        "    pred_2 = model.test_on_dataset(d_test)\n",
        "    Metrics.print_all(d_test.labels, pred_2, 'test')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvyEHdxEB18o"
      },
      "source": [
        "Результат работы пайплайна обучения и тестирования выше тоже будет оцениваться. Поэтому не забудьте присылать на проверку ноутбук с выполнеными ячейками кода с демонстрациями метрик обучения, графиками и т.п. В этом пайплайне Вам необходимо продемонстрировать работу всех реализованных дополнений, улучшений и т.п.\n",
        "\n",
        "<font color=\"red\">\n",
        "Настоятельно рекомендуется после получения пайплайна с полными результатами обучения экспортировать ноутбук в pdf (файл -> печать) и прислать этот pdf вместе с самим ноутбуком.\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzSKAvVI6uCW"
      },
      "source": [
        "### Тестирование модели на других наборах данных\n",
        "\n",
        "Ваша модель должна поддерживать тестирование на других наборах данных. Для удобства, Вам предоставляется набор данных test_tiny, который представляет собой малую часть (2% изображений) набора test. Ниже приведен фрагмент кода, который будет осуществлять тестирование для оценивания Вашей модели на дополнительных тестовых наборах данных.\n",
        "\n",
        "<font color=\"red\">\n",
        "Прежде чем отсылать задание на проверку, убедитесь в работоспособности фрагмента кода ниже.\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdY3uTt87tqv"
      },
      "outputs": [],
      "source": [
        "final_model = Model()\n",
        "final_model.load('best')\n",
        "d_test_tiny = Dataset('test_tiny')\n",
        "pred = model.test_on_dataset(d_test_tiny)\n",
        "Metrics.print_all(d_test_tiny.labels, pred, 'test-tiny')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPvyj4gscU10"
      },
      "source": [
        "Отмонтировать Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NfX35zNSvFWn"
      },
      "outputs": [],
      "source": [
        "drive.flush_and_unmount()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMyDxCDCspcI"
      },
      "source": [
        "---\n",
        "# Дополнительные \"полезности\"\n",
        "\n",
        "Ниже приведены примеры использования различных функций и библиотек, которые могут быть полезны при выполнении данного практического задания."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvLwSttCs1rB"
      },
      "source": [
        "### Измерение времени работы кода\n",
        "\n",
        "Измерять время работы какой-либо функции можно легко и непринужденно при помощи функции timeit из соответствующего модуля:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-HnLVhwE9C9S"
      },
      "outputs": [],
      "source": [
        "import timeit\n",
        "\n",
        "def factorial(n):\n",
        "    res = 1\n",
        "    for i in range(1, n + 1):\n",
        "        res *= i\n",
        "    return res\n",
        "\n",
        "\n",
        "def f():\n",
        "    return factorial(n=1000)\n",
        "\n",
        "n_runs = 128\n",
        "print(f'Function f is caluclated {n_runs} times in {timeit.timeit(f, number=n_runs)}s.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fibGVEdguOOi"
      },
      "source": [
        "### Scikit-learn\n",
        "\n",
        "Для использования \"классических\" алгоритмов машинного обучения рекомендуется использовать библиотеку scikit-learn (https://scikit-learn.org/stable/). Пример классификации изображений цифр из набора данных MNIST при помощи классификатора SVM:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXHnBzEfunAO"
      },
      "outputs": [],
      "source": [
        "# Standard scientific Python imports\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Import datasets, classifiers and performance metrics\n",
        "from sklearn import datasets, svm, metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# The digits dataset\n",
        "digits = datasets.load_digits()\n",
        "\n",
        "# The data that we are interested in is made of 8x8 images of digits, let's\n",
        "# have a look at the first 4 images, stored in the `images` attribute of the\n",
        "# dataset.  If we were working from image files, we could load them using\n",
        "# matplotlib.pyplot.imread.  Note that each image must have the same size. For these\n",
        "# images, we know which digit they represent: it is given in the 'target' of\n",
        "# the dataset.\n",
        "_, axes = plt.subplots(2, 4)\n",
        "images_and_labels = list(zip(digits.images, digits.target))\n",
        "for ax, (image, label) in zip(axes[0, :], images_and_labels[:4]):\n",
        "    ax.set_axis_off()\n",
        "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "    ax.set_title('Training: %i' % label)\n",
        "\n",
        "# To apply a classifier on this data, we need to flatten the image, to\n",
        "# turn the data in a (samples, feature) matrix:\n",
        "n_samples = len(digits.images)\n",
        "data = digits.images.reshape((n_samples, -1))\n",
        "\n",
        "# Create a classifier: a support vector classifier\n",
        "classifier = svm.SVC(gamma=0.001)\n",
        "\n",
        "# Split data into train and test subsets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    data, digits.target, test_size=0.5, shuffle=False)\n",
        "\n",
        "# We learn the digits on the first half of the digits\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Now predict the value of the digit on the second half:\n",
        "predicted = classifier.predict(X_test)\n",
        "\n",
        "images_and_predictions = list(zip(digits.images[n_samples // 2:], predicted))\n",
        "for ax, (image, prediction) in zip(axes[1, :], images_and_predictions[:4]):\n",
        "    ax.set_axis_off()\n",
        "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "    ax.set_title('Prediction: %i' % prediction)\n",
        "\n",
        "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
        "      % (classifier, metrics.classification_report(y_test, predicted)))\n",
        "disp = metrics.plot_confusion_matrix(classifier, X_test, y_test)\n",
        "disp.figure_.suptitle(\"Confusion Matrix\")\n",
        "print(\"Confusion matrix:\\n%s\" % disp.confusion_matrix)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uu3Dny5zxcVy"
      },
      "source": [
        "### Scikit-image\n",
        "\n",
        "Реализовывать различные операции для работы с изображениями можно как самостоятельно, работая с массивами numpy, так и используя специализированные библиотеки, например, scikit-image (https://scikit-image.org/). Ниже приведен пример использования Canny edge detector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5TZvy_d7xc0B"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import ndimage as ndi\n",
        "\n",
        "from skimage import feature\n",
        "\n",
        "\n",
        "# Generate noisy image of a square\n",
        "im = np.zeros((128, 128))\n",
        "im[32:-32, 32:-32] = 1\n",
        "\n",
        "im = ndi.rotate(im, 15, mode='constant')\n",
        "im = ndi.gaussian_filter(im, 4)\n",
        "im += 0.2 * np.random.random(im.shape)\n",
        "\n",
        "# Compute the Canny filter for two values of sigma\n",
        "edges1 = feature.canny(im)\n",
        "edges2 = feature.canny(im, sigma=3)\n",
        "\n",
        "# display results\n",
        "fig, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3, figsize=(8, 3),\n",
        "                                    sharex=True, sharey=True)\n",
        "\n",
        "ax1.imshow(im, cmap=plt.cm.gray)\n",
        "ax1.axis('off')\n",
        "ax1.set_title('noisy image', fontsize=20)\n",
        "\n",
        "ax2.imshow(edges1, cmap=plt.cm.gray)\n",
        "ax2.axis('off')\n",
        "ax2.set_title(r'Canny filter, $\\sigma=1$', fontsize=20)\n",
        "\n",
        "ax3.imshow(edges2, cmap=plt.cm.gray)\n",
        "ax3.axis('off')\n",
        "ax3.set_title(r'Canny filter, $\\sigma=3$', fontsize=20)\n",
        "\n",
        "fig.tight_layout()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiEWhGUQRGoH"
      },
      "source": [
        "### Tensorflow 2\n",
        "\n",
        "Для создания и обучения нейросетевых моделей можно использовать фреймворк глубокого обучения Tensorflow 2. Ниже приведен пример простейшей нейроной сети, использующейся для классификации изображений из набора данных MNIST."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDwLG7A1ReNy"
      },
      "outputs": [],
      "source": [
        "# Install TensorFlow\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "\n",
        "model.evaluate(x_test,  y_test, verbose=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbvktmLwRu8g"
      },
      "source": [
        "<font color=\"red\">\n",
        "Для эффективной работы с моделями глубокого обучения убедитесь в том, что в текущей среде Google Colab используется аппаратный ускоритель GPU или TPU. Для смены среды выберите \"среда выполнения\" -> \"сменить среду выполнения\".\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJVNOOU9Sjyf"
      },
      "source": [
        "Большое количество туториалов и примеров с кодом на Tensorflow 2 можно найти на официальном сайте https://www.tensorflow.org/tutorials?hl=ru. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVPs3pYpS0U1"
      },
      "source": [
        "Также, Вам может понадобиться написать собственный генератор данных для Tensorflow 2. Скорее всего он будет достаточно простым, и его легко можно будет реализовать, используя официальную документацию TensorFlow 2. Но, на всякий случай (если не удлось сразу разобраться или хочется вникнуть в тему более глубоко), можете посмотреть следующий отличный туториал: https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwI-T0IXyN84"
      },
      "source": [
        "### Numba\n",
        "\n",
        "В некоторых ситуациях, при ручных реализациях графовых алгоритмов, выполнение многократных вложенных циклов for в python можно существенно ускорить, используя JIT-компилятор Numba (https://numba.pydata.org/).\n",
        "Примеры использования Numba в Google Colab можно найти тут:\n",
        "1. https://colab.research.google.com/github/cbernet/maldives/blob/master/numba/numba_cuda.ipynb\n",
        "2. https://colab.research.google.com/github/evaneschneider/parallel-programming/blob/master/COMPASS_gpu_intro.ipynb \n",
        "\n",
        "> Пожалуйста, если Вы решили использовать Numba для решения этого практического задания, еще раз подумайте, нужно ли это Вам, и есть ли возможность реализовать требуемую функциональность иным способом. Используйте Numba только при реальной необходимости.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxAJ00A76LcF"
      },
      "source": [
        "### Работа с zip архивами в Google Drive\n",
        "\n",
        "Запаковка и распаковка zip архивов может пригодиться при сохранении и загрузки Вашей модели. Ниже приведен фрагмент кода, иллюстрирующий помещение нескольких файлов в zip архив с последующим чтением файлов из него. Все действия с директориями, файлами и архивами должны осущетвляться с примонтированным Google Drive.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJiKndOpPu_e"
      },
      "source": [
        "Создадим 2 изображения, поместим их в директорию tmp внутри PROJECT_DIR, запакуем директорию tmp в архив tmp.zip."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CRwgPtv-6nMP"
      },
      "outputs": [],
      "source": [
        "PROJECT_DIR = \"/dev/prak_nn_1/\"\n",
        "arr1 = np.random.rand(100, 100, 3) * 255\n",
        "arr2 = np.random.rand(100, 100, 3) * 255\n",
        "\n",
        "img1 = Image.fromarray(arr1.astype('uint8'))\n",
        "img2 = Image.fromarray(arr2.astype('uint8'))\n",
        "\n",
        "p = \"/content/drive/MyDrive/\" + PROJECT_DIR\n",
        "\n",
        "if not (Path(p) / 'tmp').exists():\n",
        "    (Path(p) / 'tmp').mkdir()\n",
        "\n",
        "img1.save(str(Path(p) / 'tmp' / 'img1.png'))\n",
        "img2.save(str(Path(p) / 'tmp' / 'img2.png'))\n",
        "\n",
        "%cd $p\n",
        "!zip -r \"tmp.zip\" \"tmp\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MykrBSWNQQlq"
      },
      "source": [
        "Распакуем архив tmp.zip в директорию tmp2 в PROJECT_DIR. Теперь внутри директории tmp2 содержится директория tmp, внутри которой находятся 2 изображения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CwSWrYIWMAus"
      },
      "outputs": [],
      "source": [
        "p = \"/content/drive/MyDrive/\" + PROJECT_DIR\n",
        "%cd $p\n",
        "!unzip -uq \"tmp.zip\" -d \"tmp2\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.4 ('py310')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "7af69d84c46e0da4f71f361435e72c01e713b5d1fcbc89c051c042527a934273"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}